{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Возьмем готовую разбивку номенклатур по категориям"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/k1s/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/k1s/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import codecs\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import cross_validation, grid_search, linear_model, metrics\n",
    "\n",
    "colnames = ['name', 'id', 'class']\n",
    "data = pandas.read_csv('nameCatIdCatName.csv', names=colnames, encoding='utf8')\n",
    "data.dropna()\n",
    "names = data['name'].tolist()\n",
    "classes = data['class'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Найдем параметры регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer =  TfidfVectorizer()\n",
    "corpus = vectorizer.fit_transform(names)\n",
    "clf = LogisticRegressionCV(n_jobs=-1, max_iter=100, refit=True)\n",
    "clf.fit(corpus, classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Построим по ним модель и проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = cross_validation.train_test_split(names, classes, \n",
    "                                                                                     test_size = 0.3, \n",
    "                                                                                     random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_id...enalty='l2', random_state=None,\n",
       "          solver='lbfgs', tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(C=10.0, class_weight='balanced', dual=False,\n",
    "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
    "           multi_class='ovr', n_jobs=-1, penalty='l2', random_state=None,\n",
    "           solver='lbfgs', tol=0.0001)\n",
    "log = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                      ('classifier', clf)])\n",
    "log.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_id...it=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=None, splitter='best'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth=2048, min_samples_leaf=4)\n",
    "log = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                      ('classifier', clf)])\n",
    "log.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.742105263158\n"
     ]
    }
   ],
   "source": [
    "score = log.score(test_data, test_labels)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полученная точность 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_params = {\n",
    "'classifier__solver' : ['newton-cg', 'sag', 'lbfgs'],\n",
    "'classifier__max_iter' : [100, 200],\n",
    "'classifier__C': [0.001, 0.1, 1, 10, 100],\n",
    "'classifier__class_weight' : ['balanced', None],\n",
    "# 'classifier__refit' : [False, True],\n",
    "'classifier__multi_class' : ['ovr', 'multinomial']\n",
    "}\n",
    "cv = cross_validation.StratifiedShuffleSplit(train_labels, n_iter = 10, test_size = 0.2, random_state = 0)\n",
    "grid_cv = grid_search.GridSearchCV(log, log_params, scoring = 'accuracy', cv = cv)\n",
    "grid_cv.fit(train_data, train_labels)\n",
    "print grid_cv.best_score_\n",
    "print grid_cv.best_params_\n",
    "# 0.854"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Раз уж мы тут все собрались, то посмотрим, что все это значит для наших  номенклатур"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "content = codecs.open(\"nom3utf.csv\", 'r', 'utf8')\n",
    "lines = [x.replace(\"\\\\\", \"\") for x in content.readlines()]\n",
    "real_test = np.random.choice(np.array(lines), size = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Серетид пор. д/инг. 25мкг+50мкг/доза 120доз \n",
      "\n",
      "0.941164512651\n",
      "ЛЕКАРСТВА ПО РЕЦЕПТАМ\n",
      "\n",
      "\n",
      "Но-шпа таб. 40мг №100\n",
      "\n",
      "0.889259218141\n",
      "СРЕДСТВА ОТ БОЛИ\n",
      "\n",
      "\n",
      "SCHOLL GELACTIV WORK СТЕЛЬКИ Д/АКТИВ РАБОТЫ Д/МУЖ Рекитт Бенкизер Хелскэр (Великобритания) Лимитед\n",
      "\n",
      "0.811672990605\n",
      "УХОД ЗА БОЛЬНЫМИ\n",
      "\n",
      "\n",
      "SENI ПЕЛЕНКА SOFT BASIC 90X60 N10\n",
      "\n",
      "0.48853554977\n",
      "УХОД ЗА БОЛЬНЫМИ\n",
      "\n",
      "\n",
      "Флюанксол табл. п.о. 1мг конт. N50 Lundbeck\n",
      "\n",
      "0.822047732727\n",
      "ЛЕКАРСТВА ПО РЕЦЕПТАМ\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicts = log.predict_proba(real_test)\n",
    "for x, predict in zip(real_test, predicts):\n",
    "    print(x)\n",
    "    for p, l in zip(predict, log.classes_):\n",
    "        if (p > 0.3):\n",
    "            print(p)\n",
    "            print(l)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну, не так уж и плохо"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
